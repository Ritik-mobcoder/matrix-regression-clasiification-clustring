{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset(\"iris\")\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n",
    "df = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"species\"])  \n",
    "y = df[\"species\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor',\n",
       "       'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'versicolor', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'setosa', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'versicolor', 'setosa', 'setosa'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.97, 0.03],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.02, 0.98],\n",
       "       [0.  , 0.99, 0.01],\n",
       "       [0.  , 0.92, 0.08],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.07, 0.93],\n",
       "       [0.  , 0.85, 0.15],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.09, 0.91],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.95, 0.05, 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.87, 0.13],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.98, 0.02],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.07, 0.93],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 0.02, 0.98],\n",
       "       [0.  , 0.02, 0.98],\n",
       "       [0.  , 0.03, 0.97],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.01, 0.99, 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.06, 0.94],\n",
       "       [0.  , 0.98, 0.02],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.05, 0.95],\n",
       "       [0.02, 0.9 , 0.08],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted') \n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Accuracy 1.0\n",
      "Precision (Weighted): 1.0\n",
      "Recall (Weighted): 1.0\n",
      "F1 Score (Weighted): 1.0\n",
      "ROC-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy\",accuracy)\n",
    "print(f\"Precision (Weighted): {precision}\")\n",
    "print(f\"Recall (Weighted): {recall}\")\n",
    "print(f\"F1 Score (Weighted): {f1}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
